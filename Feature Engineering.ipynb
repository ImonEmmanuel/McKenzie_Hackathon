{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library for eda and computations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns',200,'display.max_rows',200)\n",
    "\n",
    "#library for visualizations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "sns.set_style(style='darkgrid')\n",
    "\n",
    "#stop warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv')\n",
    "train=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping our target column\n",
    "target=[feat for feat in train.columns if feat not in test.columns]\n",
    "target=train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the target column from the data frame\n",
    "train=train.drop('y',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain,ntest=train.shape[0],test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function for renaming the column due to JSON character\"\"\"\n",
    "\n",
    "import re #Regexp Library\n",
    "\n",
    "def columns_rename(data):\n",
    "    \"\"\"This function works for columns with two or more string\n",
    "    i.e 'galactic year','Intergalactic Development Index\"\"\"\n",
    "    new_col = []\n",
    "    new_idx = []\n",
    "    new_co = []\n",
    "    galaxy = data.galaxy\n",
    "    feat = [feat for feat in data.columns if data[feat].dtypes != 'object']\n",
    "    for i in range(len(feat)):\n",
    "        review = re.sub('[^a-zA-z]', ' ', feat[i])\n",
    "        review = review.split()\n",
    "        done_review = review[0] + ' ' + review[1]\n",
    "        if len(review) >= 3:\n",
    "            done_review = done_review + ' ' + review[2]\n",
    "            if review[-1] not in done_review:\n",
    "                done_review = done_review + ' ' + review[-1]\n",
    "                new_col.append(done_review)\n",
    "            else:\n",
    "                new_col.append(done_review)\n",
    "        else:\n",
    "            new_col.append(done_review)\n",
    "    new_col = pd.Index(new_col)\n",
    "    for i in range(len(new_col)):\n",
    "        if new_col.duplicated()[i] == True:\n",
    "            new_idx.append(str(new_col[i]) +'_1')\n",
    "        else:\n",
    "            new_idx.append(str(new_col[i]))\n",
    "    new_idx = pd.Index(new_idx)\n",
    "    for i in range(len(new_idx)):\n",
    "        if new_idx.duplicated()[i] == True:\n",
    "            new_co.append(str(new_idx[i]) +'_1')\n",
    "        else:\n",
    "            new_co.append(str(new_idx[i]))\n",
    "    if len(new_co) != len(feat):\n",
    "        print('There is an error from your dataset')\n",
    "    else:\n",
    "        pass\n",
    "    data[new_co] = data[feat]\n",
    "    data_frame = data[new_co]\n",
    "    data_frame['galaxy'] = galaxy\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_train=columns_rename(train)\n",
    "new_train['target']=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test=columns_rename(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Features where gotten after running feature importance to create a lag feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feat=['Education Index','Expected years of','Gross capital formation GGP','Gross income per capita','Income Index','Intergalactic Development Index IDI',\n",
    "          'Intergalactic Development Index Rank','Interstellar Data Net population','Mean years of','Population using at services',\n",
    "          'Population using at services_1','Youth unemployment rate ratio','existence expectancy at birth','existence expectancy index','galactic year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain,ntest=new_train.shape[0], new_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([new_train, new_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating a Unique Column for the galaxy and galactic year to form a unique id\"\"\"\n",
    "def unique_id(data):\n",
    "    \"\"\"data should be the dataframe you want to iterate\"\"\"\n",
    "    uni_id = []\n",
    "    for i in range(len(data)):\n",
    "        gal_year = data['galactic year'][i]\n",
    "        gal_new = str(data.galaxy[i].split()[0]) + '_' +str(gal_year)\n",
    "        uni_id.append(gal_new)\n",
    "    data['unique_id'] = uni_id\n",
    "    return 'Column Created'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Column Created'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_id(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in galaxy\n",
      "181\n",
      "--------------------------\n",
      "Number of classes in unique_id\n",
      "1761\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#Check the number of unique classes\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(f\"Number of classes in {col}\")\n",
    "    print(df[col].nunique())\n",
    "    print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value=[(100*(df.isna().sum()/df.shape[0]))<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COL, TARGET_COL = 'unique_id', 'target'\n",
    "features = [c for c in df.columns if c not in ['unique_id', 'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Encoding\n",
    "\n",
    "We cannot use the Unique Id directly since its different for both train and test data, but we can use the the number of times each place appears in the dataframe is not same for every place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unique_id_freq'] = df['unique_id'].map(df['unique_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_features = imp_feat\n",
    "\n",
    "\n",
    "for feat in lag_features:\n",
    "    for i in range(7):\n",
    "        df[feat+'_lag'+str(i+1)] = df.groupby(['unique_id'])[feat].shift(-(i+1)).reset_index()[feat] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53931ea55f264862bbef2a5f1290c41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(1, 15)):\n",
    "    df[f'magic_{i}'] = df.sort_values(by='galactic year')[TARGET_COL].shift(i).expanding().mean().fillna(method='ffill').sort_index()\n",
    "    df[f'magic2_{i}'] = df.sort_values(by='galactic year')[TARGET_COL].shift(-i).expanding().mean().fillna(method='bfill').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new_dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can Explore the dataset for more features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
